{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806c2c01-aabd-4f26-b90b-538fd0b12068",
   "metadata": {},
   "source": [
    "<center><img src=\"img/torch.png\" alt=\"drawing\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6db0fd-43c4-49d6-b3e0-f14f66de095c",
   "metadata": {},
   "source": [
    "# Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd8121-5d10-46f0-80ae-61e248e2d10a",
   "metadata": {},
   "source": [
    "Large language models (LLMs) are deep learning algorithms that can recognize, summarize, translate, predict, and generate content using very large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfa76db-a15a-4000-863e-e429bf46a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bbe3a3-5ba5-432b-ab60-f473bf9fdc94",
   "metadata": {},
   "source": [
    "## Transformers (Attention Is All You Need)\n",
    "\n",
    "[Link](https://www.youtube.com/watch?v=ISNdQcPhsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81fe2e-3098-4e4a-a93c-1ed5c4627cc6",
   "metadata": {},
   "source": [
    "<center><img src=\"img/torch_05_01.png\" alt=\"drawing\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e488216-7baa-46f3-b859-a32ba65465c3",
   "metadata": {},
   "source": [
    "### Input Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec89775-49dd-454d-9d2b-a37bc04531df",
   "metadata": {},
   "source": [
    "<center><img src=\"img/torch_05_02.png\" alt=\"drawing\" width=\"150\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc64af5-0cc5-4df8-bda9-02d4904b1a12",
   "metadata": {},
   "source": [
    "Input embeddings allows to convert the original sentence into a 512 dimensional vector.\n",
    "\n",
    "<center><img src=\"img/torch_05_03.png\" alt=\"drawing\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eba4eb8-7a1c-485a-9af2-adf9ec62e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # Dimensions of vector\n",
    "        self.vocab_size = vocab_size # Size of vocabulary\n",
    "        self.embedding = nn.Embedding(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model) # Paper multiplies with square root of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc741d-26d2-4622-90e8-acd7e45bec49",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7314bc7-2474-48f6-8187-2c4df2ca91bc",
   "metadata": {},
   "source": [
    "<center><img src=\"img/torch_05_04.png\" alt=\"drawing\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b53201-b466-4979-90e3-5c91f34a1389",
   "metadata": {},
   "source": [
    "Positional encoding conveys to the model the information of the position of each word inside the sentence by adding another 512 dimensional vector for each word.\n",
    "\n",
    "<center><img src=\"img/torch_05_05.png\" alt=\"drawing\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e70a0f3-0edc-44ea-bfb4-a7325324fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEcnoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # Dimensions of vector\n",
    "        self.dropout = dropout # Dropout for reducing overfitting\n",
    "        \n",
    "    def forward(self, x):\n",
    "        nn.PositionalEcnoding(d_model, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d3dbb-55a4-4356-a73d-743c980739e0",
   "metadata": {},
   "source": [
    "## LLM\n",
    "\n",
    "[Tutorial](https://www.youtube.com/watch?v=kCc8FmEb1nY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c341d6-3585-427d-b43c-7629e891cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f. read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e1f1ce-47ad-444b-ba95-4ab75a918e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters: 1115481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset in characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d375a9-b70d-4ebb-bf80-2bd758fffe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[: 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596305eb-8293-4069-85c9-510544c96866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989a767-1fd4-4f93-a229-fde6094a09b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
