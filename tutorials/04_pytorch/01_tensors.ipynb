{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d057e6b1-281d-41c0-9bd4-c6eab79798e6",
   "metadata": {},
   "source": [
    "<center><img src=\"img/torch.png\" alt=\"drawing\" width=\"300\"/></center>\n",
    "\n",
    "[PyTorch](https://github.com/pytorch/pytorch) is a free and open-source machine learning framework for Python that facilitates building deep learning projects, originally developed by Meta AI and now part of the Linux Foundation umbrella. It emphasizes flexibility and allows deep learning models to be expressed in idiomatic Python. This approachability and ease of use found early adopters in the research community, and in the years since its first release, it has grown into one of the  most prominent deep learning tools across a broad range of applications.\n",
    "\n",
    "It provides two high-level features:\n",
    "* Tensor computation (like NumPy) with strong GPU acceleration.\n",
    "* Deep neural networks built on a tape-based autograd system.\n",
    "\n",
    "As Python does for programming, PyTorch provides an excellent introduction to deep learning. It minimizes cognitive overhead while focusing on flexibility and speed. It also defaults to immediate execution for operations. At the same time, PyTorch has been proven to be fully qualified for use in professional contexts for real-world, high-profile work.\n",
    "\n",
    "PyTorch library ecosystem contains some useful libraries and submodules that we will be using throughout the notebooks. Here are some of the most important ones:\n",
    "\n",
    "* **torch**: Basic Pytorch library.\n",
    "* **torch.nn**: Basic and elegantly designed submodule developed to help create and train NNs. It allows easy prototyping and the building of complex models in just a few lines of code.\n",
    "* **torch.utils**: Basic utils submodule for Pytorch.\n",
    "* **torchmetrics**: Basic metric Pytorch library.\n",
    "* **torchviz**: Basic model visualization library.\n",
    "* **torchinfo**: Basic library for summarizing a PyTorch model.\n",
    "* **torchvision**: Basic computer vision library for Pytorch.\n",
    "* **torchtext**: Basic text library for Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8326f68c-8aff-4a7d-8897-cbd1cd828662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c01002-ee78-4f11-8614-76d6a48c3c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbdced-bee0-47ef-a1bc-a537f39abb09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c935ae5-085e-471e-b9bc-fd80b35f215a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba1a904-38cf-4a5c-afba-3fac05b59994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar (rank 0 tensor)\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eb9f49-e17c-4238-bd30-79f822825650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector (rank 1 tensor)\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e661e167-bfaf-4429-aeaf-c9f8d3a36a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D-matrix (rank 2 tensor)\n",
    "matrix_2d = torch.tensor([[7,8],\n",
    "                          [9,10]])\n",
    "matrix_2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abadf21-fe11-4cd7-9031-e7198327df3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D-matrix (rank 3 tensor)\n",
    "matrix_3d = torch.tensor([[[1,2,3],\n",
    "                           [3,6,9],\n",
    "                           [2,4,5]]])\n",
    "matrix_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6e04a-90af-4f96-a87e-fa9db7d0d0bb",
   "metadata": {},
   "source": [
    "### Zeros And Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d2d5b8-3def-461e-9bcd-1c8756355a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of given dimensions full with 0\n",
    "zeros = torch.zeros(2,3,5)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cd56e1-1a3c-4a11-a4ad-259e0a1aec78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of given dimensions full with 1\n",
    "ones = torch.ones(2,3,5)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10413384-7f17-4143-9486-bbcececc677b",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ce6657-f9da-4db1-869d-d324b3a887fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7107, 0.2321, 0.0438],\n",
       "         [0.3593, 0.3914, 0.0352],\n",
       "         [0.0820, 0.4086, 0.1291]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random tensor of specific size\n",
    "random_tensor = torch.rand(size=(1,3,3))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41789c-2b0d-4ec9-b2db-1dbec2b04d5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2397ac9-a825-44d3-80bb-6e4b7746e8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of a given range\n",
    "arange = torch.arange(start=0, end=10, step=2)\n",
    "arange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0fb97-81d3-422c-bf56-cc0343d02b08",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5ab10-354e-4318-8f0d-d58d447a257b",
   "metadata": {},
   "source": [
    "We can transform Pytorch tensor to Numpy arrays and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f55057-cf73-4d24-8e9d-7a3a2c1d77d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array\n",
    "numpy_array = np.arange(10)\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e567c55-daf2-446a-9322-009184e7f9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to torch tensor\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e41cfc4f-dab4-4b7e-972a-719c848375df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch tensor to numpy array\n",
    "numpy_array = torch.Tensor.numpy(torch_tensor)\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df086101-b52e-4ce1-a0fc-e79624fa840d",
   "metadata": {},
   "source": [
    "## Indexing Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586978e-18de-4783-afc1-834a68f84605",
   "metadata": {},
   "source": [
    "We can **index** tensors just like we do in Python lists or NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29064b69-bac1-4456-85e3-7a528bb74105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), tensor(7))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first and second value of vector\n",
    "vector[0], vector[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2301f2aa-2c1d-4e11-9978-4e11869633bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the actual value instead of a tensor.\n",
    "vector[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "186f5813-3c89-4045-8fd6-ed6e81ae4a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing notation for tensor (matrix_3d[0,:,1:3] also works)\n",
    "matrix_3d[0][:][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00a065-36d1-42be-b008-d5dbb58229f2",
   "metadata": {},
   "source": [
    "## Attributes Of Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69d713-745a-4517-8fcf-0c51ecfbc1bd",
   "metadata": {},
   "source": [
    "We can access certain **attributes** of tensors as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2388e-8f92-4b11-a07c-9aae458715dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Type: `dtype`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8d1b6-8e91-48cc-ac40-b0cef3f0a2ce",
   "metadata": {},
   "source": [
    "The `dtype` argument (deliberately similar to the standard NumPy argument of the same name) specifies the numerical data type that will be contained in the tensor. The data type specifies the possible values the tensor can hold (integers versus floating point numbers) and the number of bytes per value.\n",
    "\n",
    "Here’s a list of the possible values for the dtype argument:\n",
    "- `torch.float32` or `torch.float: 32-bit` floating-point\n",
    "- `torch.float64` or `torch.double`: 64-bit, double-precision floating-point \n",
    "- `torch.float16` or `torch.half`: 16-bit, half-precision floating-point\n",
    "- `torch.int8`: signed 8-bit integers\n",
    "- `torch.uint8`: unsigned 8-bit integers\n",
    "- `torch.int16` or `torch.short`: signed 16-bit integers\n",
    "- `torch.int32` or `torch.int`: signed 32-bit integers\n",
    "- `torch.int64` or `torch.long`: signed 64-bit integers\n",
    "- `torch.bool`: Boolean\n",
    "\n",
    "The default data type for tensors is 32-bit floating-point `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c349804f-774d-4563-9b0f-1a2ff276a8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data type of tensor\n",
    "matrix_3d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62dc7ebd-723f-41a7-a054-77505cb2fb95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from one data type to another\n",
    "matrix_3d = matrix_3d.to(torch.float64)\n",
    "matrix_3d.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e2161-7a40-44d4-b433-772c393785eb",
   "metadata": {},
   "source": [
    "### Rank (Number Of Dimensions): `ndim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b9b62-1102-4c4a-a9ba-51c6ec0953fd",
   "metadata": {},
   "source": [
    "Attribute `ndim` informs as about the rank or number of dimensions of a tensor.\n",
    "\n",
    "<center><img src=\"img/torch_01_01.png\" alt=\"drawing\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "994fd9a3-6892-4022-a4e3-0754f468d9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank (number of dimensions) of a tensor\n",
    "scalar.ndim, vector.ndim, matrix_2d.ndim, matrix_3d.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aff0dd-5e11-48f5-9837-c6f237ba1438",
   "metadata": {},
   "source": [
    "### Shape (Number Of Elements): `shape`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520d1e0-87f0-44b5-b7df-2cef187862af",
   "metadata": {},
   "source": [
    "Attribute `shape` informs us about the size of the tensor along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "742a08bf-11f4-4170-a1a9-18fb44e650c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([2]), torch.Size([2, 2]), torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of elements for each dimension of a tensor\n",
    "scalar.shape, vector.shape, matrix_2d.shape, matrix_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214ae69-105b-4fe6-abee-89e77a2a361e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here is an illustration example of what `matrix_3d.shape` is exactly.\n",
    "\n",
    "<center><img src=\"img/torch_01_02.png\" alt=\"drawing\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958fc00-9f8c-43c6-95eb-b650d1550a90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manipulating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747061c-cb0a-47cc-acb2-4bdb8074fa0f",
   "metadata": {},
   "source": [
    "\n",
    "As we will see in upcoming sections, certain operations require that the input tensors have a certain number of dimensions (rank) associated with a certain number of elements (shape). Thus, we might need to change the shape of a tensor, add a new dimension, or squeeze an unnecessary dimension. PyTorch provides useful functions (or operations) to achieve this:\n",
    "\n",
    "* **Transpose**: Transposes a tensor.\n",
    "* **Reshape**: Reshapes an input tensor to a defined shape.\n",
    "* **View**: Returns a view of a tensor of certain shape keeping the same memory as the original tensor. Changing the view changes the original tensor because they share the same memory.\n",
    "* **Squeeze**: Removes all `1` dimensions from a tensor.\n",
    "* **Unsqueeze**: Adds a `1` dimension to a target tensor ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b236ba15-93c3-45a8-a48e-d7069536a31f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[3,4,5]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fae7c46-83ae-43bd-84db-1d2bd62da813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4],\n",
       "        [3, 5]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose tensor\n",
    "a.transpose(dim0=0, dim1=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d1136d2-2fc9-4cfd-a98a-897a92addeca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape tensor from 2x3 to 3x2\n",
    "a.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9b35208-6801-436b-b9af-4d145e6b7b35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view of tensor (use same memory)\n",
    "a.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c48ba8-0608-462c-acea-6f21af72dda4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsqueeze tensor\n",
    "unsqueezed_a = a.unsqueeze(1)\n",
    "unsqueezed_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a5bfb64-f6f9-43ac-8012-f54775be66cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze tensor\n",
    "unsqueezed_a.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56abf2-8d05-4d43-a0b9-648b4cbe43b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdc1f5-6f15-4089-98dd-abe55a87e953",
   "metadata": {},
   "source": [
    "Applying mathematical operations, in particular linear algebra operations, is necessary for building most machine learning models. In this subsection, we will cover some widely used linear algebra operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c594567-0d1d-4cda-a8e4-37bc18f9650b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[10, 7], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684935f0-da5d-4169-9cb1-c16ff25444df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20, 17],\n",
       "         [13, 14]]),\n",
       " tensor([[100,  70],\n",
       "         [ 30,  40]]),\n",
       " tensor([[ 0, -3],\n",
       "         [-7, -6]]),\n",
       " tensor([[1.0000, 0.7000],\n",
       "         [0.3000, 0.4000]]),\n",
       " tensor([[10000000000,   282475249],\n",
       "         [      59049,     1048576]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition, Multiplication, Subtraction, Division, Power\n",
    "tensor + 10, tensor * 10, tensor - 10, tensor /10, tensor**10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35274838-7af9-4cb4-b294-a9a6dd31c7fa",
   "metadata": {},
   "source": [
    "We can also use the following function for the basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cac1652d-9799-498f-93a5-d15a171efdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[3, 6]], dtype=torch.float32)\n",
    "b = torch.tensor([[2, 2]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc968897-75a4-4f17-b534-faa8df3c29c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 8.]]),\n",
       " tensor([[ 6., 12.]]),\n",
       " tensor([[18.]]),\n",
       " tensor([[1.5000, 3.0000]]),\n",
       " tensor([[ 9., 36.]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element wise addition\n",
    "addition = torch.add(a,b) # a.add(b) also works\n",
    "\n",
    "# Element wise multiplication\n",
    "multiplication = torch.multiply(a,b) # a.multiply(b) also works\n",
    "\n",
    "# Matrix multiplication (transpose needed to match tensor dimensions)\n",
    "matrix_multiplication = torch.matmul(a, b.transpose(0,1)) # a.matmul(b.transpose(0,1)) also works\n",
    "\n",
    "# Element wise division\n",
    "division = torch.divide(a, b) # a.divide(b) also works\n",
    "\n",
    "# Element wise rise to power\n",
    "power = torch.pow(a,b) # a.pow(b) also works\n",
    "\n",
    "addition, multiplication, matrix_multiplication, division, power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b23c1-e26c-4614-b4ed-0fe76d9be640",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some more basic operation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cad00872-56c9-48bc-a4e2-afcb0c8eb114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9., 36.]]),\n",
       " tensor([[1.7321, 2.4495]]),\n",
       " tensor([[1.0986, 1.7918]]),\n",
       " tensor([[3., 6.]]),\n",
       " tensor(3.),\n",
       " tensor(0),\n",
       " tensor(6.),\n",
       " tensor(1),\n",
       " tensor(4.5000),\n",
       " tensor(9.))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square\n",
    "square = torch.square(a) # a.square() also works\n",
    "\n",
    "# Square root (needs changing type)\n",
    "sqrt = torch.sqrt(a) # a.sqrt() also works\n",
    "\n",
    "# Log (needs changing type)\n",
    "log = torch.log(a) # a.log() also works\n",
    "\n",
    "# Absolute values\n",
    "absolute_value = torch.abs(a) # a.abs() also works\n",
    "\n",
    "# Minimum\n",
    "minimum = torch.min(a) # a.min() also works\n",
    "\n",
    "# Minimum element position\n",
    "argmin = torch.argmin(a) # a.argmin() also works\n",
    "\n",
    "# Maximum\n",
    "maximum = torch.max(a) # a.max() also works\n",
    "\n",
    "# Maximum element position\n",
    "argmax = torch.argmax(a) # a.argmax() also works\n",
    "\n",
    "# Mean\n",
    "mean = torch.mean(a) # a.mean() also works\n",
    "\n",
    "# Sum\n",
    "sumation = torch.sum(a) # a.sum() also works\n",
    "\n",
    "square, sqrt, log, absolute_value, minimum, argmin, maximum, argmax, mean, sumation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d66a1-c063-4709-8589-c70320c7bdc6",
   "metadata": {},
   "source": [
    "## Splitting & Combining Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192beb1-625e-4568-80e4-933decfe134d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this subsection, we will cover PyTorch operations for splitting a tensor into multiple tensors, or the reverse: stacking and concatenating multiple tensors into a single one.\n",
    "\n",
    "Assume that we have a single tensor, and we want to split it into two or more tensors. For this, PyTorch provides a convenient `torch.chunk()` function, which divides an input tensor into a list of equally sized tensors. We can determine the desired number of splits as an integer using the chunks argument to split a tensor along the desired dimension specified by the dim argument. In this case, the total size of the input tensor along the specified dimension must be divisible by the desired number of splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4fee73d-7e8b-49ef-8b3d-924ce8c3264b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7484, 0.2492, 0.5632, 0.8910, 0.5715, 0.1486])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(6)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14630e42-bb5d-48e9-b0c3-f1a018ab3c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7484, 0.2492]), tensor([0.5632, 0.8910]), tensor([0.5715, 0.1486]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunk tensor\n",
    "torch.chunk(t, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827c3bc-1977-418d-ba69-115631d1d784",
   "metadata": {},
   "source": [
    "Alternatively, we can provide the desired sizes in a list using the `torch.split(`) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dda796b3-1f8c-4f85-8e35-8a8c34a3fcef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7484, 0.2492, 0.5632, 0.8910]), tensor([0.5715, 0.1486]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split tensor\n",
    "torch.split(t, [4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099463c-0f9a-49be-8815-040a4904516d",
   "metadata": {},
   "source": [
    "Sometimes, we are working with multiple tensors and need to concatenate or stack them to create a single tensor. In this case, PyTorch functions such as `torch.cat()` and `torch.stack()` come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1295699e-e709-46b0-8028-364f582079d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]), tensor([0., 0., 0.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(3)\n",
    "B = torch.zeros(3)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90347315-9e4a-4044-a402-657eeb4f7f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate tensors together\n",
    "torch.cat([A, B], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eab8042f-a77a-47c9-bf2f-c574ab38293d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors together\n",
    "torch.stack([A, B], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c341922-f1a2-4e1e-88bb-87a28ca1f7fb",
   "metadata": {},
   "source": [
    "## Computation Graphs\n",
    "PyTorch performs its computations based on a Directed Acyclic Graph (DAG). It uses this computation graph to derive relationships between tensors from the input all the way to the output. The computation graph is simply a network of nodes. Each node resembles an operation, which applies a function to its input tensor or tensors and returns zero or more tensors as the output. PyTorch builds this computation graph and uses it to compute the gradients accordingly.\n",
    "\n",
    "<center><img src=\"img/torch_01_03.png\" alt=\"drawing\" width=\"250\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b016283-4b9b-457c-9dae-3b9bd4f0bbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a graph for evaluating z = 2 × (a – b) + c,\n",
    "def compute_z(a, b, c):\n",
    "    r1 = torch.sub(a, b)\n",
    "    r2 = torch.mul(r1, 2)\n",
    "    z = torch.add(r2, c)\n",
    "    return z\n",
    "\n",
    "# To carry out the computation, we call `compute_z` with tensor objects as function arguments\n",
    "compute_z(torch.tensor(1), torch.tensor(2), torch.tensor(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eba095-cefb-4104-887d-7aea14d17f7b",
   "metadata": {},
   "source": [
    "In PyTorch, a special tensor object for which gradients need to be computed allows us to store and update the parameters of our models during training. Such a tensor can be created by just assigning `requires_grad` to `True` on user-specified initial values. \n",
    "\n",
    "***Note**: Only tensors of floating point and complex dtype can require gradients)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c836b70-e345-4335-97f5-aa0d0e45eac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `requires_grad` is set to `False` by default\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(a.requires_grad)\n",
    "\n",
    "# `requires_grad` can be set to `True` by running `requires_grad_()`\n",
    "a.requires_grad_()\n",
    "print(a.requires_grad)\n",
    "\n",
    "# Or it can be set to `True` upon construction\n",
    "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ab725-ac70-445d-a16d-ee29688b6b6d",
   "metadata": {},
   "source": [
    "PyTorch supports automatic differentiation, which can be thought of as an implementation of the chain rule for computing gradients of nested functions. When we define a series of operations that results in some output or even intermediate tensors, PyTorch provides a context for calculating gradients of these computed tensors with respect to its dependent nodes in the computation graph. To compute these gradients, we can call the `backward` method from the `torch.autograd` module. It computes the sum of gradients of the given tensor with regard to leaf nodes (terminal nodes) in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e6956cb-eb0f-440f-85d4-342fbdc513fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_fn(w,b,x): \n",
    "    return torch.add(torch.mul(w, x), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce3708a5-59f5-48f4-b50a-3a160b341e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters (weight and bias)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.5, requires_grad=True)\n",
    "\n",
    "# a datapoint (x_0,y_0)\n",
    "x_0 = torch.tensor([1.4])\n",
    "y_0 = torch.tensor([2.1])\n",
    "\n",
    "# compute linear function\n",
    "y = linear_fn(w=w, b=b, x=x_0)\n",
    "\n",
    "# compute loss\n",
    "loss = (y_0 - y).pow(2).sum()\n",
    "\n",
    "# compute gradient manually by computing derivatives\n",
    "dloss_dw = (2 * (y_0 - y) * (-x_0)).sum()\n",
    "dloss_db = (2 * (y_0 - y) * (-1)).sum()\n",
    "\n",
    "# compute gradients with `backward`\n",
    "loss.backward()\n",
    "\n",
    "# verify that they are the same\n",
    "(dloss_dw == w.grad).item(), (dloss_db == b.grad).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
